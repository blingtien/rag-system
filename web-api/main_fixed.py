#!/usr/bin/env python3
"""
RAG-Anything Web API Server - LightRAG WebUI Compatible Version
ä¿®å¤ç‰ˆæœ¬ï¼šå®Œå…¨å…¼å®¹LightRAG WebUIçš„APIæ¥å£æ ¼å¼å’Œé”™è¯¯å¤„ç†
"""

import os
import sys
import asyncio
import logging
import traceback
from pathlib import Path
from typing import List, Dict, Any, Optional
import tempfile
import json
from datetime import datetime
import hashlib
import uuid

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv("/home/ragsvr/projects/ragsystem/RAG-Anything/.env")
load_dotenv()

from fastapi import FastAPI, HTTPException, UploadFile, File, Form, BackgroundTasks, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import structlog

# é…ç½®ç»“æ„åŒ–æ—¥å¿—
logging.basicConfig(
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    level=logging.INFO,
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = structlog.get_logger(__name__)

# æ¥å…¥å®é™…RAG-Anythingç”Ÿäº§ç³»ç»Ÿ
project_root = Path(__file__).parent.parent / "RAG-Anything"
sys.path.insert(0, str(project_root))

try:
    from raganything import RAGAnything, RAGAnythingConfig
    from lightrag.llm.openai import openai_complete_if_cache, openai_embed
    from lightrag.utils import EmbeddingFunc
    RAG_AVAILABLE = True
    logger.info("âœ… RAG-Anythingæ ¸å¿ƒç³»ç»Ÿå·²å¯¼å…¥")
except ImportError as e:
    RAG_AVAILABLE = False
    logger.warning(f"âš ï¸ RAG-Anythingæ ¸å¿ƒç³»ç»Ÿå¯¼å…¥å¤±è´¥: {e}")
    logger.warning("ğŸ”„ å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œ")

# === å®Œå…¨å…¼å®¹LightRAG WebUIçš„æ•°æ®æ¨¡å‹ ===

class LightragNode(BaseModel):
    id: str
    labels: List[str]
    properties: Dict[str, Any]

class LightragEdge(BaseModel):
    id: str
    source: str
    target: str
    type: str
    properties: Dict[str, Any]

class LightragGraph(BaseModel):
    nodes: List[LightragNode]
    edges: List[LightragEdge]

class LightragStatus(BaseModel):
    status: str = "healthy"
    working_directory: str
    input_directory: str = ""
    configuration: Dict[str, Any]
    pipeline_busy: bool = False
    core_version: Optional[str] = "1.2.7"
    api_version: Optional[str] = "1.0.0"
    auth_mode: Optional[str] = "disabled"
    webui_title: Optional[str] = "RAG-Anything WebUI"
    webui_description: Optional[str] = "å¤šæ¨¡æ€RAGç³»ç»ŸWebç•Œé¢"

class QueryRequest(BaseModel):
    query: str
    mode: str = "hybrid"  # naive, local, global, hybrid, mix, bypass
    only_need_context: Optional[bool] = False
    only_need_prompt: Optional[bool] = False
    response_type: Optional[str] = "Multiple Paragraphs"
    stream: Optional[bool] = False
    top_k: Optional[int] = 10
    chunk_top_k: Optional[int] = 5
    max_entity_tokens: Optional[int] = 2000
    max_relation_tokens: Optional[int] = 2000
    max_total_tokens: Optional[int] = 8000
    conversation_history: Optional[List[Dict[str, str]]] = None
    history_turns: Optional[int] = 3
    user_prompt: Optional[str] = None
    enable_rerank: Optional[bool] = True

class QueryResponse(BaseModel):
    response: str

class DocActionResponse(BaseModel):
    status: str  # success, partial_success, failure, duplicated
    message: str
    track_id: Optional[str] = None

class DocStatusResponse(BaseModel):
    id: str
    content_summary: str
    content_length: int
    status: str  # pending, processing, processed, failed
    created_at: str
    updated_at: str
    track_id: Optional[str] = None
    chunks_count: Optional[int] = 0
    error_msg: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None
    file_path: str

class DocsStatusesResponse(BaseModel):
    statuses: Dict[str, List[DocStatusResponse]]

class ErrorResponse(BaseModel):
    error: str
    detail: str
    timestamp: str
    request_id: str

# === FastAPIåº”ç”¨é…ç½® ===

app = FastAPI(
    title="RAG-Anything Web API - LightRAG Compatible",
    description="å®Œå…¨å…¼å®¹LightRAG WebUIçš„å¤šæ¨¡æ€RAGç³»ç»ŸWebæ¥å£",
    version="1.2.7"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€RAGå®ä¾‹
rag_instance: Optional[RAGAnything] = None

# === å¢å¼ºçš„é”™è¯¯å¤„ç† ===

class APIError(Exception):
    def __init__(self, message: str, status_code: int = 500, detail: str = ""):
        self.message = message
        self.status_code = status_code
        self.detail = detail
        super().__init__(self.message)

@app.exception_handler(APIError)
async def api_error_handler(request: Request, exc: APIError):
    """è‡ªå®šä¹‰APIé”™è¯¯å¤„ç†å™¨"""
    request_id = str(uuid.uuid4())
    
    logger.error(
        "APIé”™è¯¯",
        error=exc.message,
        detail=exc.detail,
        status_code=exc.status_code,
        request_id=request_id,
        path=request.url.path,
        method=request.method
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content=ErrorResponse(
            error=exc.message,
            detail=exc.detail,
            timestamp=datetime.now().isoformat(),
            request_id=request_id
        ).dict()
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """é€šç”¨å¼‚å¸¸å¤„ç†å™¨"""
    request_id = str(uuid.uuid4())
    
    logger.error(
        "æœªå¤„ç†çš„å¼‚å¸¸",
        error=str(exc),
        traceback=traceback.format_exc(),
        request_id=request_id,
        path=request.url.path,
        method=request.method
    )
    
    return JSONResponse(
        status_code=500,
        content=ErrorResponse(
            error="Internal Server Error",
            detail=str(exc),
            timestamp=datetime.now().isoformat(),
            request_id=request_id
        ).dict()
    )

# === RAGå®ä¾‹ç®¡ç† ===

async def get_rag_instance() -> RAGAnything:
    """è·å–RAGå®ä¾‹ï¼Œå¸¦å®Œæ•´é”™è¯¯å¤„ç†"""
    global rag_instance
    
    if not RAG_AVAILABLE:
        raise APIError("RAGæ ¸å¿ƒç³»ç»Ÿä¸å¯ç”¨", 503, "RAG-Anythingå¯¼å…¥å¤±è´¥")
    
    if rag_instance is None:
        try:
            logger.info("æ­£åœ¨åˆå§‹åŒ–RAGå®ä¾‹...")
            
            # åˆå§‹åŒ–RAGé…ç½®
            config = RAGAnythingConfig(
                working_dir="/home/ragsvr/projects/ragsystem/RAG-Anything/rag_storage",
                parser="mineru",
                parse_method="auto",
                enable_image_processing=True,
                enable_table_processing=True,
                enable_equation_processing=True,
            )
            
            # æ£€æŸ¥DeepSeek APIé…ç½®
            deepseek_api_key = os.getenv("DEEPSEEK_API_KEY") or os.getenv("LLM_BINDING_API_KEY")
            deepseek_base_url = os.getenv("LLM_BINDING_HOST", "https://api.deepseek.com/v1")
            
            if not deepseek_api_key:
                raise APIError("æœªé…ç½®LLM APIå¯†é’¥", 500, "è¯·è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡")
            
            logger.info("ğŸš€ ä½¿ç”¨DeepSeek APIä½œä¸ºLLMåç«¯")
            
            # é…ç½®DeepSeek API
            os.environ["OPENAI_API_KEY"] = deepseek_api_key
            os.environ["OPENAI_BASE_URL"] = deepseek_base_url
            
            # LLMå‡½æ•°
            def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
                return openai_complete_if_cache(
                    "deepseek-chat",
                    prompt,
                    system_prompt=system_prompt,
                    history_messages=history_messages,
                    api_key=deepseek_api_key,
                    base_url=deepseek_base_url,
                    **kwargs,
                )

            # Visionæ¨¡å‹å‡½æ•°
            def vision_model_func(prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs):
                if messages:
                    return openai_complete_if_cache(
                        "deepseek-vl", "", None, [], messages=messages,
                        api_key=deepseek_api_key, base_url=deepseek_base_url, **kwargs
                    )
                elif image_data:
                    return openai_complete_if_cache(
                        "deepseek-vl", "", None, [],
                        messages=[
                            {"role": "system", "content": system_prompt} if system_prompt else None,
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": prompt},
                                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}},
                                ],
                            }
                        ],
                        api_key=deepseek_api_key, base_url=deepseek_base_url, **kwargs
                    )
                else:
                    return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

            # åµŒå…¥å‡½æ•°
            try:
                sys.path.append("/home/ragsvr/projects/ragsystem/RAG-Anything")
                from simple_qwen_embed import qwen_embed
                embedding_func = EmbeddingFunc(
                    embedding_dim=1024,
                    max_token_size=512,
                    func=qwen_embed,
                )
                logger.info("âœ… ä½¿ç”¨æœ¬åœ°Qwen3åµŒå…¥æ¨¡å‹")
            except ImportError:
                logger.warning("âš ï¸ qwen_embedä¸å¯ç”¨ï¼Œä½¿ç”¨OpenAIåµŒå…¥")
                embedding_func = EmbeddingFunc(
                    embedding_dim=1536,
                    max_token_size=8192,
                    func=openai_embed,
                )
            
            # åˆ›å»ºRAGå®ä¾‹
            rag_instance = RAGAnything(
                config=config,
                llm_model_func=llm_model_func,
                vision_model_func=vision_model_func,
                embedding_func=embedding_func
            )
            
            # ç¡®ä¿RAGå·²åˆå§‹åŒ–
            await rag_instance._ensure_lightrag_initialized()
            
            logger.info("âœ… RAGå®ä¾‹åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ RAGå®ä¾‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise APIError(f"RAGå®ä¾‹åˆå§‹åŒ–å¤±è´¥: {str(e)}", 500, traceback.format_exc())
    
    return rag_instance

# === å®Œå…¨å…¼å®¹LightRAG WebUIçš„APIæ¥å£ ===

@app.get("/health", response_model=LightragStatus)
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ - å®Œå…¨å…¼å®¹LightRAG WebUI"""
    try:
        rag = await get_rag_instance()
        
        working_dir = "/home/ragsvr/projects/ragsystem/RAG-Anything/rag_storage"
        if hasattr(rag, 'config') and hasattr(rag.config, 'working_dir'):
            working_dir = rag.config.working_dir
        
        configuration = {
            "llm_binding": "deepseek",
            "llm_binding_host": os.getenv("LLM_BINDING_HOST", "https://api.deepseek.com/v1"),
            "llm_model": "deepseek-chat",
            "embedding_binding": "qwen_local",
            "embedding_binding_host": "local",
            "embedding_model": "Qwen3-Embedding-0.6B",
            "max_tokens": 4000,
            "kv_storage": "json",
            "doc_status_storage": "json", 
            "graph_storage": "json",
            "vector_storage": "json",
            "workspace": working_dir,
            "summary_language": "zh_CN",
            "force_llm_summary_on_merge": True,
            "max_parallel_insert": 4,
            "max_async": 16,
            "embedding_func_max_async": 16,
            "embedding_batch_num": 32,
            "cosine_threshold": 0.2,
            "min_rerank_score": 0.0,
            "related_chunk_number": 10
        }
        
        return LightragStatus(
            status="healthy",
            working_directory=working_dir,
            input_directory=working_dir,
            configuration=configuration,
            pipeline_busy=False,
            core_version="1.2.7",
            api_version="1.0.0", 
            auth_mode="disabled",
            webui_title="RAG-Anything WebUI",
            webui_description="å¤šæ¨¡æ€RAGç³»ç»ŸWebç•Œé¢"
        )
    except APIError:
        raise
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise APIError("å¥åº·æ£€æŸ¥å¤±è´¥", 503, str(e))

@app.get("/documents", response_model=DocsStatusesResponse)
async def get_documents():
    """è·å–æ–‡æ¡£çŠ¶æ€ - å®Œå…¨å…¼å®¹LightRAG WebUIæ ¼å¼"""
    try:
        rag_storage_path = "/home/ragsvr/projects/ragsystem/RAG-Anything/rag_storage"
        doc_status_file = os.path.join(rag_storage_path, "kv_store_doc_status.json")
        
        processed_docs = []
        pending_docs = []
        processing_docs = []
        failed_docs = []
        
        if os.path.exists(doc_status_file):
            try:
                with open(doc_status_file, 'r', encoding='utf-8') as f:
                    doc_statuses = json.load(f)
                
                for doc_id, doc_info in doc_statuses.items():
                    doc_data = DocStatusResponse(
                        id=doc_id,
                        content_summary=doc_info.get("content_summary", "")[:200] + "..." if len(doc_info.get("content_summary", "")) > 200 else doc_info.get("content_summary", ""),
                        content_length=doc_info.get("content_length", 0),
                        status=doc_info.get("status", "unknown"),
                        created_at=doc_info.get("created_at", ""),
                        updated_at=doc_info.get("updated_at", ""),
                        track_id=doc_info.get("track_id", ""),
                        chunks_count=doc_info.get("chunks_count", 0),
                        file_path=doc_info.get("file_path", ""),
                        metadata=doc_info.get("metadata", {})
                    )
                    
                    status = doc_info.get("status", "unknown")
                    if status == "processed":
                        processed_docs.append(doc_data)
                    elif status == "pending":
                        pending_docs.append(doc_data)
                    elif status == "processing":
                        processing_docs.append(doc_data)
                    elif status == "failed":
                        failed_docs.append(doc_data)
                
                logger.info(f"ä»æ•°æ®åº“åŠ è½½æ–‡æ¡£: processed={len(processed_docs)}, pending={len(pending_docs)}, processing={len(processing_docs)}, failed={len(failed_docs)}")
            except json.JSONDecodeError as e:
                logger.error(f"è§£ææ–‡æ¡£çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
                raise APIError("æ–‡æ¡£çŠ¶æ€æ•°æ®æŸå", 500, str(e))
        else:
            logger.warning(f"æ–‡æ¡£çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: {doc_status_file}")
        
        return DocsStatusesResponse(
            statuses={
                "processed": processed_docs,
                "pending": pending_docs,
                "processing": processing_docs,
                "failed": failed_docs
            }
        )
    except APIError:
        raise
    except Exception as e:
        logger.error(f"è·å–æ–‡æ¡£å¤±è´¥: {e}")
        raise APIError("è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥", 500, str(e))

@app.post("/documents/upload", response_model=DocActionResponse)
async def upload_document(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...)
):
    """æ–‡æ¡£ä¸Šä¼  - å®Œå…¨å…¼å®¹LightRAG WebUIæ ¼å¼"""
    try:
        # éªŒè¯æ–‡ä»¶
        if not file.filename:
            raise APIError("æ–‡ä»¶åä¸èƒ½ä¸ºç©º", 400)
        
        if file.size and file.size > 100 * 1024 * 1024:  # 100MBé™åˆ¶
            raise APIError("æ–‡ä»¶å¤§å°è¶…è¿‡100MBé™åˆ¶", 400)
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.filename).suffix) as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name
        
        track_id = f"upload_{int(datetime.now().timestamp())}_{hashlib.md5(file.filename.encode()).hexdigest()[:8]}"
        
        # æ·»åŠ åå°å¤„ç†ä»»åŠ¡
        background_tasks.add_task(
            process_document_background,
            tmp_file_path,
            file.filename,
            track_id
        )
        
        logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file.filename}, track_id: {track_id}")
        
        return DocActionResponse(
            status="success",
            message=f"æ–‡ä»¶ {file.filename} ä¸Šä¼ æˆåŠŸï¼Œæ­£åœ¨å¤„ç†ä¸­...",
            track_id=track_id
        )
    except APIError:
        raise
    except Exception as e:
        logger.error(f"æ–‡æ¡£ä¸Šä¼ å¤±è´¥: {e}")
        raise APIError("æ–‡æ¡£ä¸Šä¼ å¤±è´¥", 500, str(e))

async def process_document_background(file_path: str, filename: str, track_id: str):
    """åå°å¤„ç†æ–‡æ¡£ - å¢å¼ºé”™è¯¯å¤„ç†"""
    try:
        logger.info(f"å¼€å§‹å¤„ç†æ–‡æ¡£: {filename}")
        
        rag = await get_rag_instance()
        
        # å¤„ç†æ–‡æ¡£
        output_dir = "/home/ragsvr/projects/ragsystem/web-api/output"
        os.makedirs(output_dir, exist_ok=True)
        
        await rag.process_document_complete(
            file_path=file_path,
            output_dir=output_dir, 
            parse_method="auto"
        )
        
        logger.info(f"æ–‡æ¡£å¤„ç†å®Œæˆ: {filename}")
        
    except Exception as e:
        logger.error(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {filename}, é”™è¯¯: {e}")
        
        # æ›´æ–°æ–‡æ¡£çŠ¶æ€ä¸ºå¤±è´¥
        try:
            rag_storage_path = "/home/ragsvr/projects/ragsystem/RAG-Anything/rag_storage"
            doc_status_file = os.path.join(rag_storage_path, "kv_store_doc_status.json")
            
            doc_statuses = {}
            if os.path.exists(doc_status_file):
                with open(doc_status_file, 'r', encoding='utf-8') as f:
                    doc_statuses = json.load(f)
            
            doc_statuses[track_id] = {
                "status": "failed",
                "error_msg": str(e),
                "file_path": filename,
                "updated_at": datetime.now().isoformat()
            }
            
            with open(doc_status_file, 'w', encoding='utf-8') as f:
                json.dump(doc_statuses, f, ensure_ascii=False, indent=2)
                
        except Exception as status_error:
            logger.error(f"æ›´æ–°æ–‡æ¡£çŠ¶æ€å¤±è´¥: {status_error}")
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.unlink(file_path)
        except:
            pass

@app.post("/query", response_model=QueryResponse)
async def query_rag(query_request: QueryRequest):
    """RAGæŸ¥è¯¢æ¥å£ - å®Œå…¨å…¼å®¹LightRAG WebUI"""
    try:
        if not query_request.query.strip():
            raise APIError("æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º", 400)
        
        rag = await get_rag_instance()
        
        logger.info(f"æ‰§è¡ŒæŸ¥è¯¢: {query_request.query[:50]}..., æ¨¡å¼: {query_request.mode}")
        
        # æ‰§è¡ŒæŸ¥è¯¢
        result = await rag.aquery(
            query_request.query,
            mode=query_request.mode,
            vlm_enhanced=False
        )
        
        logger.info("æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸ")
        
        return QueryResponse(response=result)
        
    except APIError:
        raise
    except Exception as e:
        logger.error(f"RAGæŸ¥è¯¢å¤±è´¥: {e}")
        raise APIError("æŸ¥è¯¢æ‰§è¡Œå¤±è´¥", 500, str(e))

@app.post("/query/stream")
async def query_stream(query_request: QueryRequest):
    """æµå¼æŸ¥è¯¢æ¥å£ - å…¼å®¹LightRAG WebUI"""
    try:
        if not query_request.query.strip():
            raise APIError("æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º", 400)
        
        async def generate():
            try:
                rag = await get_rag_instance()
                
                # ä¸ºæµå¼å“åº”æ¨¡æ‹Ÿåˆ†å—è¾“å‡º
                result = await rag.aquery(
                    query_request.query,
                    mode=query_request.mode,
                    vlm_enhanced=False
                )
                
                # å°†ç»“æœåˆ†æˆå°å—æµå¼è¾“å‡º
                words = result.split()
                chunk_size = 5  # æ¯æ¬¡è¾“å‡º5ä¸ªè¯
                
                for i in range(0, len(words), chunk_size):
                    chunk = " ".join(words[i:i+chunk_size])
                    if i + chunk_size < len(words):
                        chunk += " "
                    
                    yield f'{{"response": "{chunk}"}}\n'
                    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿæµå¼å»¶è¿Ÿ
                
            except Exception as e:
                logger.error(f"æµå¼æŸ¥è¯¢å¤±è´¥: {e}")
                yield f'{{"error": "{str(e)}"}}\n'
        
        return StreamingResponse(
            generate(),
            media_type="application/x-ndjson",
            headers={"Cache-Control": "no-cache"}
        )
        
    except APIError:
        raise
    except Exception as e:
        logger.error(f"æµå¼æŸ¥è¯¢å¤±è´¥: {e}")
        raise APIError("æµå¼æŸ¥è¯¢å¤±è´¥", 500, str(e))

@app.get("/graphs")
async def get_graphs(label: str = "", max_depth: int = 3, max_nodes: int = 100):
    """è·å–çŸ¥è¯†å›¾è°± - å…¼å®¹LightRAG WebUI"""
    try:
        # æ¨¡æ‹Ÿå›¾è°±æ•°æ®ï¼Œå®é™…åº”è¯¥ä»RAGç³»ç»Ÿè·å–
        nodes = [
            LightragNode(
                id=f"node_{i}",
                labels=["Entity"],
                properties={"name": f"å®ä½“{i}", "type": "concept"}
            ) for i in range(min(max_nodes, 10))
        ]
        
        edges = [
            LightragEdge(
                id=f"edge_{i}",
                source=f"node_{i}",
                target=f"node_{i+1}",
                type="RELATED_TO",
                properties={"weight": 0.8}
            ) for i in range(min(len(nodes)-1, 9))
        ]
        
        return LightragGraph(nodes=nodes, edges=edges)
        
    except Exception as e:
        logger.error(f"è·å–å›¾è°±å¤±è´¥: {e}")
        raise APIError("è·å–çŸ¥è¯†å›¾è°±å¤±è´¥", 500, str(e))

@app.get("/graph/label/list")
async def get_graph_labels():
    """è·å–å›¾è°±æ ‡ç­¾åˆ—è¡¨ - å…¼å®¹LightRAG WebUI"""
    try:
        # æ¨¡æ‹Ÿæ ‡ç­¾æ•°æ®
        return ["Entity", "Concept", "Person", "Organization", "Event"]
    except Exception as e:
        logger.error(f"è·å–å›¾è°±æ ‡ç­¾å¤±è´¥: {e}")
        raise APIError("è·å–å›¾è°±æ ‡ç­¾å¤±è´¥", 500, str(e))

@app.get("/")
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "message": "RAG-Anything Web API - LightRAG Compatible",
        "version": "1.2.7",
        "docs": "/docs",
        "health": "/health",
        "compatibility": "LightRAG WebUI Compatible"
    }

if __name__ == "__main__":
    import uvicorn
    
    logger.info("ğŸš€ å¯åŠ¨RAG-Anything Web APIæœåŠ¡å™¨ (LightRAGå…¼å®¹ç‰ˆ)")
    
    uvicorn.run(
        "main_fixed:app",
        host="0.0.0.0",
        port=8001,
        reload=True,
        log_level="info"
    )