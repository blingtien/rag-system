# æ‰¹é‡å¤„ç†é‡æ„è¿ç§»æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—è¯´æ˜å¦‚ä½•å®‰å…¨åœ°å°†ç°æœ‰çš„æ‰¹é‡å¤„ç†ä»£ç è¿ç§»åˆ°æ–°çš„æ¶æ„ï¼Œè§£å†³cache_metricsåˆå§‹åŒ–é—®é¢˜å’Œå…¶ä»–æ¶æ„ç¼ºé™·ã€‚

## è¿ç§»æ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šé›†æˆæ–°çš„æ‰¹å¤„ç†åè°ƒå™¨ï¼ˆç«‹å³å¯ç”¨ï¼‰

1. **å¯¼å…¥æ–°æ¨¡å—**

åœ¨ `rag_api_server.py` ä¸­æ·»åŠ å¯¼å…¥ï¼š

```python
# åœ¨æ–‡ä»¶é¡¶éƒ¨çš„å¯¼å…¥éƒ¨åˆ†æ·»åŠ 
from batch_processing_refactor import (
    BatchProcessingCoordinator,
    BatchContext,
    CacheMetrics,
    ProcessingState
)
```

2. **åˆ›å»ºåè°ƒå™¨å®ä¾‹**

åœ¨ `initialize_rag()` å‡½æ•°åæ·»åŠ ï¼š

```python
# å…¨å±€æ‰¹å¤„ç†åè°ƒå™¨
batch_coordinator: Optional[BatchProcessingCoordinator] = None

async def initialize_batch_coordinator():
    """åˆå§‹åŒ–æ‰¹å¤„ç†åè°ƒå™¨"""
    global batch_coordinator, cache_enhanced_processor
    
    if batch_coordinator is not None:
        return batch_coordinator
    
    # ç¡®ä¿RAGå’Œç¼“å­˜å¤„ç†å™¨å·²åˆå§‹åŒ–
    await initialize_rag()
    
    # åˆ›å»ºæ‰¹å¤„ç†åè°ƒå™¨
    batch_coordinator = BatchProcessingCoordinator(
        documents_store=documents,
        tasks_store=tasks,
        rag_instance=rag_instance,
        cache_processor=cache_enhanced_processor
    )
    
    logger.info("æ‰¹å¤„ç†åè°ƒå™¨åˆå§‹åŒ–æˆåŠŸ")
    return batch_coordinator
```

3. **æ›´æ–°startupäº‹ä»¶**

```python
@app.on_event("startup")
async def startup_event():
    """æœåŠ¡å¯åŠ¨æ—¶åˆå§‹åŒ–"""
    logger.info("=== æœåŠ¡å™¨å¯åŠ¨åˆå§‹åŒ–å¼€å§‹ ===")
    
    # ç°æœ‰åˆå§‹åŒ–ä»£ç ...
    
    # æ·»åŠ æ‰¹å¤„ç†åè°ƒå™¨åˆå§‹åŒ–
    logger.info("åˆå§‹åŒ–æ‰¹å¤„ç†åè°ƒå™¨...")
    await initialize_batch_coordinator()
    
    logger.info("=== æœåŠ¡å™¨å¯åŠ¨å®Œæˆ ===")
```

### ç¬¬äºŒæ­¥ï¼šæ›¿æ¢æ‰¹é‡å¤„ç†ç«¯ç‚¹ï¼ˆå®‰å…¨è¿ç§»ï¼‰

åˆ›å»ºæ–°çš„ç«¯ç‚¹ï¼Œä¸åŸæœ‰ç«¯ç‚¹å¹¶å­˜ï¼Œä¾¿äºA/Bæµ‹è¯•ï¼š

```python
@app.post("/api/v2/documents/process/batch")
async def process_documents_batch_v2(request: BatchProcessRequest):
    """
    æ”¹è¿›çš„æ‰¹é‡å¤„ç†ç«¯ç‚¹ - ä½¿ç”¨æ–°æ¶æ„
    è§£å†³äº†cache_metricsåˆå§‹åŒ–é—®é¢˜
    """
    batch_operation_id = str(uuid.uuid4())
    
    # ç¡®ä¿åè°ƒå™¨å·²åˆå§‹åŒ–
    if not batch_coordinator:
        await initialize_batch_coordinator()
    
    logger.info(f"ğŸš€ [V2] å¼€å§‹æ‰¹é‡å¤„ç† {len(request.document_ids)} ä¸ªæ–‡æ¡£")
    
    try:
        # ä½¿ç”¨æ–°çš„åè°ƒå™¨å¤„ç†
        result = await batch_coordinator.process_batch(
            batch_id=batch_operation_id,
            document_ids=request.document_ids,
            options={
                "output_dir": OUTPUT_DIR,
                "parse_method": request.parse_method or "auto",
                "max_workers": int(os.getenv("MAX_CONCURRENT_PROCESSING", "3"))
            }
        )
        
        # æ„å»ºå“åº”
        return BatchProcessResponse(
            success=result["success"],
            started_count=result["valid_count"],
            failed_count=result["invalid_count"],
            total_requested=result["total_requested"],
            results=result.get("results", {}).get("results", []),
            batch_operation_id=batch_operation_id,
            message=f"æ‰¹é‡å¤„ç†{'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}",
            cache_performance=result["cache_performance"]  # ä¿è¯å§‹ç»ˆæœ‰å€¼
        )
        
    except Exception as e:
        logger.error(f"V2æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")
        
        # å³ä½¿å‡ºé”™ä¹Ÿè¿”å›å®Œæ•´çš„å“åº”ï¼ŒåŒ…å«åˆå§‹åŒ–çš„cache_metrics
        return BatchProcessResponse(
            success=False,
            started_count=0,
            failed_count=len(request.document_ids),
            total_requested=len(request.document_ids),
            results=[],
            batch_operation_id=batch_operation_id,
            message=f"æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}",
            cache_performance=CacheMetrics().to_dict()  # å§‹ç»ˆè¿”å›æœ‰æ•ˆçš„metrics
        )
```

### ç¬¬ä¸‰æ­¥ï¼šé€æ­¥è¿ç§»ï¼ˆæ¨èæ–¹å¼ï¼‰

1. **å¹¶è¡Œè¿è¡Œæ–°æ—§ç‰ˆæœ¬**
   - ä¿æŒåŸæœ‰çš„ `/api/v1/documents/process/batch` ç«¯ç‚¹ä¸å˜
   - æ–°å¢ `/api/v2/documents/process/batch` ç«¯ç‚¹ä½¿ç”¨æ–°æ¶æ„
   - é€šè¿‡å‰ç«¯é…ç½®æˆ–åŠŸèƒ½å¼€å…³æ§åˆ¶ä½¿ç”¨å“ªä¸ªç‰ˆæœ¬

2. **ç›‘æ§å’Œå¯¹æ¯”**
   ```python
   # æ·»åŠ ç›‘æ§ä¸­é—´ä»¶
   @app.middleware("http")
   async def monitor_batch_processing(request: Request, call_next):
       if "/process/batch" in request.url.path:
           start_time = time.time()
           response = await call_next(request)
           duration = time.time() - start_time
           
           version = "v2" if "/v2/" in request.url.path else "v1"
           logger.info(f"Batch processing {version} took {duration:.2f}s")
           
           # è®°å½•æŒ‡æ ‡ç”¨äºå¯¹æ¯”
           if version == "v2":
               # è®°å½•æ–°ç‰ˆæœ¬çš„æ€§èƒ½æŒ‡æ ‡
               pass
       else:
           response = await call_next(request)
       
       return response
   ```

3. **æ¸è¿›å¼åˆ‡æ¢**
   ```python
   # ä½¿ç”¨åŠŸèƒ½å¼€å…³æ§åˆ¶æµé‡
   USE_NEW_BATCH_PROCESSOR = os.getenv("USE_NEW_BATCH_PROCESSOR", "false").lower() == "true"
   
   @app.post("/api/v1/documents/process/batch")
   async def process_documents_batch_adaptive(request: BatchProcessRequest):
       """è‡ªé€‚åº”æ‰¹é‡å¤„ç†ç«¯ç‚¹ - æ ¹æ®é…ç½®é€‰æ‹©å®ç°"""
       if USE_NEW_BATCH_PROCESSOR:
           # è½¬å‘åˆ°æ–°å®ç°
           return await process_documents_batch_v2(request)
       else:
           # ä½¿ç”¨åŸæœ‰å®ç°
           return await process_documents_batch(request)
   ```

### ç¬¬å››æ­¥ï¼šéªŒè¯å’Œæµ‹è¯•

1. **å•å…ƒæµ‹è¯•**

åˆ›å»ºæµ‹è¯•æ–‡ä»¶ `test_batch_processing_refactor.py`ï¼š

```python
import pytest
from batch_processing_refactor import (
    BatchProcessingCoordinator,
    CacheMetrics,
    BatchContext,
    ProcessingState
)

@pytest.mark.asyncio
async def test_cache_metrics_always_initialized():
    """éªŒè¯cache_metricså§‹ç»ˆè¢«åˆå§‹åŒ–"""
    # å‡†å¤‡
    coordinator = BatchProcessingCoordinator({}, {})
    
    # æ‰§è¡Œ - ç©ºæ–‡æ¡£åˆ—è¡¨
    result = await coordinator.process_batch(
        batch_id="test-batch",
        document_ids=[]
    )
    
    # éªŒè¯
    assert "cache_performance" in result
    assert result["cache_performance"] is not None
    assert isinstance(result["cache_performance"], dict)
    assert "cache_hits" in result["cache_performance"]
    assert "cache_misses" in result["cache_performance"]

@pytest.mark.asyncio
async def test_error_preserves_cache_metrics():
    """éªŒè¯é”™è¯¯æƒ…å†µä¸‹cache_metricsä»ç„¶å­˜åœ¨"""
    # å‡†å¤‡ - æ— æ•ˆçš„æ–‡æ¡£ID
    coordinator = BatchProcessingCoordinator({}, {})
    
    # æ‰§è¡Œ
    result = await coordinator.process_batch(
        batch_id="test-batch",
        document_ids=["non-existent-doc"]
    )
    
    # éªŒè¯
    assert not result["success"]
    assert "cache_performance" in result
    assert result["cache_performance"] is not None
```

2. **é›†æˆæµ‹è¯•**

```python
# æµ‹è¯•æ–°æ—§ç‰ˆæœ¬çš„å…¼å®¹æ€§
async def test_version_compatibility():
    """æµ‹è¯•æ–°æ—§ç‰ˆæœ¬APIçš„å…¼å®¹æ€§"""
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_request = {
        "document_ids": ["doc1", "doc2"],
        "parse_method": "auto"
    }
    
    # æµ‹è¯•V1ç«¯ç‚¹
    response_v1 = await client.post("/api/v1/documents/process/batch", json=test_request)
    assert response_v1.status_code == 200
    data_v1 = response_v1.json()
    
    # æµ‹è¯•V2ç«¯ç‚¹
    response_v2 = await client.post("/api/v2/documents/process/batch", json=test_request)
    assert response_v2.status_code == 200
    data_v2 = response_v2.json()
    
    # éªŒè¯å“åº”ç»“æ„ä¸€è‡´
    assert "cache_performance" in data_v1
    assert "cache_performance" in data_v2
    assert data_v2["cache_performance"] is not None
```

### ç¬¬äº”æ­¥ï¼šæ€§èƒ½ç›‘æ§

æ·»åŠ æ€§èƒ½ç›‘æ§ä»¥éªŒè¯æ”¹è¿›æ•ˆæœï¼š

```python
# åœ¨ rag_api_server.py ä¸­æ·»åŠ 
class BatchProcessingMetrics:
    """æ‰¹å¤„ç†æ€§èƒ½æŒ‡æ ‡æ”¶é›†"""
    
    def __init__(self):
        self.v1_metrics = []
        self.v2_metrics = []
    
    def record_v1(self, duration: float, success: bool, cache_metrics: dict):
        self.v1_metrics.append({
            "timestamp": datetime.now().isoformat(),
            "duration": duration,
            "success": success,
            "cache_metrics": cache_metrics
        })
    
    def record_v2(self, duration: float, success: bool, cache_metrics: dict):
        self.v2_metrics.append({
            "timestamp": datetime.now().isoformat(),
            "duration": duration,
            "success": success,
            "cache_metrics": cache_metrics
        })
    
    def get_comparison(self):
        """è·å–æ€§èƒ½å¯¹æ¯”"""
        return {
            "v1": {
                "avg_duration": sum(m["duration"] for m in self.v1_metrics) / len(self.v1_metrics) if self.v1_metrics else 0,
                "success_rate": sum(1 for m in self.v1_metrics if m["success"]) / len(self.v1_metrics) if self.v1_metrics else 0,
                "total_processed": len(self.v1_metrics)
            },
            "v2": {
                "avg_duration": sum(m["duration"] for m in self.v2_metrics) / len(self.v2_metrics) if self.v2_metrics else 0,
                "success_rate": sum(1 for m in self.v2_metrics if m["success"]) / len(self.v2_metrics) if self.v2_metrics else 0,
                "total_processed": len(self.v2_metrics)
            }
        }

# åˆ›å»ºå…¨å±€æŒ‡æ ‡æ”¶é›†å™¨
batch_metrics = BatchProcessingMetrics()
```

### ç¬¬å…­æ­¥ï¼šå›æ»šè®¡åˆ’

å¦‚æœæ–°ç‰ˆæœ¬å‡ºç°é—®é¢˜ï¼Œå¯ä»¥å¿«é€Ÿå›æ»šï¼š

1. **ç¯å¢ƒå˜é‡æ§åˆ¶**
   ```bash
   # åˆ‡æ¢åˆ°æ–°ç‰ˆæœ¬
   export USE_NEW_BATCH_PROCESSOR=true
   
   # å›æ»šåˆ°æ—§ç‰ˆæœ¬
   export USE_NEW_BATCH_PROCESSOR=false
   ```

2. **çƒ­åˆ‡æ¢æ”¯æŒ**
   ```python
   @app.post("/api/admin/batch-processor/switch")
   async def switch_batch_processor(use_new: bool):
       """è¿è¡Œæ—¶åˆ‡æ¢æ‰¹å¤„ç†å™¨ç‰ˆæœ¬"""
       global USE_NEW_BATCH_PROCESSOR
       USE_NEW_BATCH_PROCESSOR = use_new
       
       return {
           "success": True,
           "message": f"å·²åˆ‡æ¢åˆ°{'æ–°' if use_new else 'æ—§'}ç‰ˆæ‰¹å¤„ç†å™¨",
           "current_version": "v2" if use_new else "v1"
       }
   ```

## éªŒè¯æ£€æŸ¥æ¸…å•

è¿ç§»å®Œæˆåï¼Œè¯·éªŒè¯ä»¥ä¸‹é¡¹ç›®ï¼š

- [ ] cache_metricsåœ¨æ‰€æœ‰æƒ…å†µä¸‹éƒ½è¢«æ­£ç¡®åˆå§‹åŒ–
- [ ] é”™è¯¯å¤„ç†ä¸ä¼šå¯¼è‡´UnboundLocalError
- [ ] æ‰¹é‡å¤„ç†æ€§èƒ½ä¸åŸç‰ˆæœ¬ç›¸å½“æˆ–æ›´å¥½
- [ ] æ‰€æœ‰ç°æœ‰APIå“åº”æ ¼å¼ä¿æŒå…¼å®¹
- [ ] æ—¥å¿—è®°å½•æ­£å¸¸å·¥ä½œ
- [ ] WebSocketé€šçŸ¥æ­£å¸¸å‘é€
- [ ] ç¼“å­˜ç»Ÿè®¡æ­£ç¡®è®°å½•å’ŒæŠ¥å‘Š
- [ ] å¯ä»¥åœ¨æ–°æ—§ç‰ˆæœ¬é—´æ— ç¼åˆ‡æ¢

## é—®é¢˜æ’æŸ¥

### é—®é¢˜1ï¼šcache_metricsä»ç„¶æœªå®šä¹‰

**æ£€æŸ¥ç‚¹ï¼š**
1. ç¡®è®¤ä½¿ç”¨äº†æ–°çš„BatchProcessingCoordinator
2. éªŒè¯CacheMetricsç±»è¢«æ­£ç¡®å¯¼å…¥
3. æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–åœ°æ–¹ç›´æ¥è®¿é—®cache_metricså˜é‡

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# å§‹ç»ˆä½¿ç”¨CacheMetricsç±»
cache_metrics = CacheMetrics()  # è€Œä¸æ˜¯ cache_metrics = {}
```

### é—®é¢˜2ï¼šæ€§èƒ½ä¸‹é™

**æ£€æŸ¥ç‚¹ï¼š**
1. æ£€æŸ¥æ˜¯å¦æ­£ç¡®é…ç½®äº†å¹¶å‘æ•°
2. éªŒè¯ç¼“å­˜æ˜¯å¦æ­£å¸¸å·¥ä½œ
3. æŸ¥çœ‹æ˜¯å¦æœ‰é¢å¤–çš„åŒæ­¥æ“ä½œ

**è§£å†³æ–¹æ¡ˆï¼š**
è°ƒæ•´MAX_CONCURRENT_PROCESSINGç¯å¢ƒå˜é‡

### é—®é¢˜3ï¼šAPIå“åº”æ ¼å¼ä¸å…¼å®¹

**æ£€æŸ¥ç‚¹ï¼š**
1. å¯¹æ¯”æ–°æ—§å“åº”ç»“æ„
2. æ£€æŸ¥å‰ç«¯æ˜¯å¦ä¾èµ–ç‰¹å®šå­—æ®µ

**è§£å†³æ–¹æ¡ˆï¼š**
ä½¿ç”¨é€‚é…å™¨æ¨¡å¼è½¬æ¢å“åº”æ ¼å¼

## æ€»ç»“

é€šè¿‡è¿™ä¸ªæ¸è¿›å¼è¿ç§»æ–¹æ¡ˆï¼Œå¯ä»¥ï¼š

1. **ç«‹å³è§£å†³**cache_metricsåˆå§‹åŒ–é—®é¢˜
2. **é€æ­¥æ”¹å–„**ä»£ç æ¶æ„è´¨é‡
3. **ä¿æŒç³»ç»Ÿ**ç¨³å®šè¿è¡Œ
4. **æä¾›å›æ»š**èƒ½åŠ›ä»¥åº”å¯¹æ„å¤–æƒ…å†µ

å»ºè®®æŒ‰ç…§è¿ç§»æ­¥éª¤é€æ­¥å®æ–½ï¼Œå¹¶åœ¨æ¯ä¸ªé˜¶æ®µè¿›è¡Œå……åˆ†æµ‹è¯•ã€‚