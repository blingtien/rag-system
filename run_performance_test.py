#!/usr/bin/env python3
"""
RAG-Anything API å¿«é€Ÿæ€§èƒ½æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯æ€§èƒ½åˆ†ææŠ¥å‘Šä¸­è¯†åˆ«çš„ä¸»è¦é—®é¢˜
"""

import asyncio
import aiohttp
import time
import psutil
import json
import statistics
from pathlib import Path
from typing import List, Dict, Any
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent / "RAG-Anything"))


class QuickPerformanceTest:
    """å¿«é€Ÿæ€§èƒ½æµ‹è¯•ç±»"""
    
    def __init__(self, api_url: str = "http://127.0.0.1:8001"):
        self.api_url = api_url
        self.results = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "tests": {},
            "issues_found": [],
            "recommendations": []
        }
    
    async def check_api_health(self) -> bool:
        """æ£€æŸ¥APIå¥åº·çŠ¶æ€"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.api_url}/health", timeout=5) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        print(f"âœ… APIå¥åº·æ£€æŸ¥é€šè¿‡: {data['status']}")
                        return True
        except Exception as e:
            print(f"âŒ APIå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False
        return False
    
    async def test_serial_batch_processing(self, num_files: int = 5) -> Dict[str, Any]:
        """æµ‹è¯•æ‰¹å¤„ç†æ˜¯å¦çœŸçš„å¹¶è¡Œ"""
        print(f"\nğŸ” æµ‹è¯•æ‰¹å¤„ç†å¹¶å‘æ€§ ({num_files} ä¸ªæ–‡ä»¶)...")
        
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_files = []
        for i in range(num_files):
            file_path = f"/tmp/test_doc_{i}.txt"
            with open(file_path, 'w') as f:
                f.write(f"This is test document {i}\n" * 100)
            test_files.append(file_path)
        
        try:
            async with aiohttp.ClientSession() as session:
                # ä¸Šä¼ æ–‡ä»¶
                document_ids = []
                upload_start = time.time()
                
                for file_path in test_files:
                    with open(file_path, 'rb') as f:
                        data = aiohttp.FormData()
                        data.add_field('file', f, filename=Path(file_path).name)
                        
                        async with session.post(f"{self.api_url}/api/v1/documents/upload", data=data) as resp:
                            if resp.status == 200:
                                result = await resp.json()
                                document_ids.append(result['document_id'])
                
                upload_time = time.time() - upload_start
                
                # æ‰¹é‡å¤„ç†
                batch_start = time.time()
                batch_data = {
                    "document_ids": document_ids,
                    "parser": "direct_text",  # ä½¿ç”¨æœ€å¿«çš„è§£æå™¨
                    "parse_method": "auto"
                }
                
                async with session.post(
                    f"{self.api_url}/api/v1/documents/process/batch",
                    json=batch_data,
                    timeout=300
                ) as resp:
                    batch_result = await resp.json()
                
                batch_time = time.time() - batch_start
                
                # åˆ†æç»“æœ
                expected_parallel_time = batch_time / num_files  # å¦‚æœçœŸæ­£å¹¶è¡Œçš„é¢„æœŸæ—¶é—´
                efficiency = (expected_parallel_time * num_files) / batch_time * 100
                
                result = {
                    "num_files": num_files,
                    "upload_time": upload_time,
                    "batch_processing_time": batch_time,
                    "avg_time_per_file": batch_time / num_files,
                    "parallel_efficiency": efficiency,
                    "is_truly_parallel": efficiency > 150  # å¦‚æœæ•ˆç‡>150%è¯´æ˜æœ‰å¹¶è¡Œ
                }
                
                if not result["is_truly_parallel"]:
                    self.results["issues_found"].append(
                        "æ‰¹å¤„ç†å®é™…æ˜¯ä¸²è¡Œæ‰§è¡Œï¼Œæœªå®ç°çœŸæ­£çš„å¹¶è¡Œå¤„ç†"
                    )
                    self.results["recommendations"].append(
                        "ä½¿ç”¨ asyncio.gather() æˆ– concurrent.futures å®ç°çœŸæ­£çš„å¹¶è¡Œå¤„ç†"
                    )
                
                print(f"  æ‰¹å¤„ç†æ—¶é—´: {batch_time:.2f}s")
                print(f"  å¹³å‡æ¯æ–‡ä»¶: {result['avg_time_per_file']:.2f}s")
                print(f"  å¹¶è¡Œæ•ˆç‡: {efficiency:.1f}%")
                print(f"  æ˜¯å¦å¹¶è¡Œ: {'âœ… æ˜¯' if result['is_truly_parallel'] else 'âŒ å¦'}")
                
                return result
                
        except Exception as e:
            print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
            return {"error": str(e)}
        finally:
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            for file_path in test_files:
                if os.path.exists(file_path):
                    os.remove(file_path)
    
    async def test_memory_leak(self, iterations: int = 10) -> Dict[str, Any]:
        """æµ‹è¯•å†…å­˜æ³„æ¼"""
        print(f"\nğŸ” æµ‹è¯•å†…å­˜æ³„æ¼ ({iterations} æ¬¡è¿­ä»£)...")
        
        memory_usage = []
        process = psutil.Process()
        
        # åˆå§‹å†…å­˜
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_usage.append(initial_memory)
        
        try:
            async with aiohttp.ClientSession() as session:
                for i in range(iterations):
                    # åˆ›å»ºå¹¶ä¸Šä¼ å°æ–‡ä»¶
                    file_path = f"/tmp/mem_test_{i}.txt"
                    with open(file_path, 'w') as f:
                        f.write(f"Memory test {i}\n" * 10)
                    
                    # ä¸Šä¼ 
                    with open(file_path, 'rb') as f:
                        data = aiohttp.FormData()
                        data.add_field('file', f, filename=f"mem_test_{i}.txt")
                        
                        async with session.post(f"{self.api_url}/api/v1/documents/upload", data=data) as resp:
                            await resp.json()
                    
                    # æ¸…ç†æ–‡ä»¶
                    os.remove(file_path)
                    
                    # è®°å½•å†…å­˜
                    current_memory = process.memory_info().rss / 1024 / 1024
                    memory_usage.append(current_memory)
                    
                    if i % 3 == 0:
                        print(f"  è¿­ä»£ {i+1}/{iterations}: å†…å­˜ {current_memory:.1f}MB (+{current_memory - initial_memory:.1f}MB)")
        
        except Exception as e:
            print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
        
        # åˆ†æå†…å­˜å¢é•¿
        memory_growth = memory_usage[-1] - memory_usage[0]
        avg_growth_per_iteration = memory_growth / iterations
        
        result = {
            "initial_memory_mb": initial_memory,
            "final_memory_mb": memory_usage[-1],
            "total_growth_mb": memory_growth,
            "avg_growth_per_iteration_mb": avg_growth_per_iteration,
            "has_memory_leak": avg_growth_per_iteration > 0.5  # æ¯æ¬¡è¿­ä»£å¢é•¿>0.5MBè§†ä¸ºæ³„æ¼
        }
        
        if result["has_memory_leak"]:
            self.results["issues_found"].append(
                f"æ£€æµ‹åˆ°å†…å­˜æ³„æ¼ï¼šæ¯æ¬¡æ“ä½œå¢é•¿ {avg_growth_per_iteration:.2f}MB"
            )
            self.results["recommendations"].append(
                "å®ç°å®šæœŸæ¸…ç†æœºåˆ¶ï¼Œé™åˆ¶å…¨å±€å˜é‡å¤§å°ï¼Œä½¿ç”¨å¼±å¼•ç”¨"
            )
        
        print(f"  å†…å­˜å¢é•¿: {memory_growth:.1f}MB")
        print(f"  æ¯æ¬¡è¿­ä»£: {avg_growth_per_iteration:.2f}MB")
        print(f"  å†…å­˜æ³„æ¼: {'âš ï¸ æ˜¯' if result['has_memory_leak'] else 'âœ… å¦'}")
        
        return result
    
    async def test_cache_efficiency(self) -> Dict[str, Any]:
        """æµ‹è¯•ç¼“å­˜æ•ˆç‡"""
        print(f"\nğŸ” æµ‹è¯•ç¼“å­˜æ•ˆç‡...")
        
        # åˆ›å»ºç›¸åŒå†…å®¹çš„æ–‡ä»¶
        content = "This is a test document for cache testing.\n" * 100
        file1 = "/tmp/cache_test_1.txt"
        file2 = "/tmp/cache_test_2.txt"
        
        with open(file1, 'w') as f:
            f.write(content)
        
        # ç­‰å¾…ä»¥ç¡®ä¿ä¸åŒçš„æ—¶é—´æˆ³
        await asyncio.sleep(1)
        
        with open(file2, 'w') as f:
            f.write(content)
        
        try:
            async with aiohttp.ClientSession() as session:
                results = []
                
                for file_path in [file1, file2]:
                    # ä¸Šä¼ å¹¶å¤„ç†
                    start_time = time.time()
                    
                    with open(file_path, 'rb') as f:
                        data = aiohttp.FormData()
                        data.add_field('file', f, filename=Path(file_path).name)
                        
                        async with session.post(f"{self.api_url}/api/v1/documents/upload", data=data) as resp:
                            upload_result = await resp.json()
                    
                    document_id = upload_result['document_id']
                    
                    async with session.post(f"{self.api_url}/api/v1/documents/{document_id}/process") as resp:
                        process_result = await resp.json()
                    
                    # ç­‰å¾…å¤„ç†å®Œæˆ
                    task_id = process_result['task_id']
                    completed = False
                    polls = 0
                    
                    while not completed and polls < 60:
                        await asyncio.sleep(1)
                        async with session.get(f"{self.api_url}/api/v1/tasks/{task_id}") as resp:
                            task_status = await resp.json()
                            if task_status['task']['status'] in ['completed', 'failed']:
                                completed = True
                        polls += 1
                    
                    process_time = time.time() - start_time
                    results.append(process_time)
                
                # åˆ†æç¼“å­˜æ•ˆæœ
                cache_speedup = results[0] / results[1] if results[1] > 0 else 1.0
                
                result = {
                    "first_process_time": results[0],
                    "second_process_time": results[1],
                    "cache_speedup": cache_speedup,
                    "cache_working": cache_speedup > 1.5
                }
                
                if not result["cache_working"]:
                    self.results["issues_found"].append(
                        "ç¼“å­˜æœªç”Ÿæ•ˆï¼šç›¸åŒå†…å®¹çš„æ–‡ä»¶å¤„ç†æ—¶é—´ç›¸è¿‘"
                    )
                    self.results["recommendations"].append(
                        "ä½¿ç”¨å†…å®¹å“ˆå¸Œè€Œéæ–‡ä»¶ä¿®æ”¹æ—¶é—´ä½œä¸ºç¼“å­˜é”®"
                    )
                
                print(f"  é¦–æ¬¡å¤„ç†: {results[0]:.2f}s")
                print(f"  äºŒæ¬¡å¤„ç†: {results[1]:.2f}s")
                print(f"  ç¼“å­˜åŠ é€Ÿ: {cache_speedup:.2f}x")
                print(f"  ç¼“å­˜ç”Ÿæ•ˆ: {'âœ… æ˜¯' if result['cache_working'] else 'âŒ å¦'}")
                
                return result
                
        except Exception as e:
            print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
            return {"error": str(e)}
        finally:
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            for file_path in [file1, file2]:
                if os.path.exists(file_path):
                    os.remove(file_path)
    
    async def test_concurrent_requests(self, num_concurrent: int = 10) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†èƒ½åŠ›"""
        print(f"\nğŸ” æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç† ({num_concurrent} ä¸ªå¹¶å‘)...")
        
        async def single_request(index: int) -> float:
            """å•ä¸ªè¯·æ±‚"""
            start_time = time.time()
            
            try:
                async with aiohttp.ClientSession() as session:
                    # å¥åº·æ£€æŸ¥è¯·æ±‚ï¼ˆè½»é‡çº§ï¼‰
                    async with session.get(f"{self.api_url}/health", timeout=10) as resp:
                        await resp.json()
                
                return time.time() - start_time
            except Exception:
                return -1
        
        # ä¸²è¡Œæ‰§è¡Œ
        serial_start = time.time()
        serial_times = []
        for i in range(num_concurrent):
            t = await single_request(i)
            if t > 0:
                serial_times.append(t)
        serial_total = time.time() - serial_start
        
        # å¹¶å‘æ‰§è¡Œ
        concurrent_start = time.time()
        tasks = [single_request(i) for i in range(num_concurrent)]
        concurrent_times = await asyncio.gather(*tasks)
        concurrent_total = time.time() - concurrent_start
        
        # è¿‡æ»¤æœ‰æ•ˆç»“æœ
        concurrent_times = [t for t in concurrent_times if t > 0]
        
        result = {
            "num_concurrent": num_concurrent,
            "serial_total_time": serial_total,
            "concurrent_total_time": concurrent_total,
            "speedup": serial_total / concurrent_total if concurrent_total > 0 else 1.0,
            "avg_response_time": statistics.mean(concurrent_times) if concurrent_times else 0,
            "success_rate": len(concurrent_times) / num_concurrent * 100
        }
        
        if result["speedup"] < 2.0:
            self.results["issues_found"].append(
                f"å¹¶å‘å¤„ç†èƒ½åŠ›å·®ï¼š{num_concurrent}ä¸ªå¹¶å‘è¯·æ±‚ä»…è·å¾— {result['speedup']:.1f}x åŠ é€Ÿ"
            )
            self.results["recommendations"].append(
                "ä¼˜åŒ–äº‹ä»¶å¾ªç¯ï¼Œé¿å…é˜»å¡æ“ä½œï¼Œä½¿ç”¨å¼‚æ­¥I/O"
            )
        
        print(f"  ä¸²è¡Œæ—¶é—´: {serial_total:.2f}s")
        print(f"  å¹¶å‘æ—¶é—´: {concurrent_total:.2f}s")
        print(f"  åŠ é€Ÿæ¯”: {result['speedup']:.2f}x")
        print(f"  æˆåŠŸç‡: {result['success_rate']:.1f}%")
        
        return result
    
    async def test_resource_usage(self) -> Dict[str, Any]:
        """æµ‹è¯•èµ„æºä½¿ç”¨æƒ…å†µ"""
        print(f"\nğŸ” æµ‹è¯•èµ„æºä½¿ç”¨...")
        
        # è·å–ç³»ç»Ÿèµ„æº
        cpu_percent = psutil.cpu_percent(interval=2)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        # æ£€æŸ¥è¿›ç¨‹æ•°
        rag_processes = []
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                cmdline = ' '.join(proc.info['cmdline'] or [])
                if 'rag_api_server' in cmdline or 'RAG-Anything' in cmdline:
                    rag_processes.append(proc)
            except:
                pass
        
        result = {
            "cpu_usage_percent": cpu_percent,
            "memory_usage_percent": memory.percent,
            "memory_available_gb": memory.available / (1024**3),
            "disk_usage_percent": disk.percent,
            "disk_free_gb": disk.free / (1024**3),
            "num_rag_processes": len(rag_processes),
            "cpu_underutilized": cpu_percent < 30,
            "memory_pressure": memory.percent > 80,
            "disk_pressure": disk.percent > 90
        }
        
        if result["cpu_underutilized"]:
            self.results["issues_found"].append(
                f"CPUåˆ©ç”¨ç‡ä½ï¼šä»… {cpu_percent:.1f}%"
            )
            self.results["recommendations"].append(
                "å¢åŠ å¹¶å‘å¤„ç†ï¼Œä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†CPUå¯†é›†å‹ä»»åŠ¡"
            )
        
        if result["memory_pressure"]:
            self.results["issues_found"].append(
                f"å†…å­˜å‹åŠ›é«˜ï¼šä½¿ç”¨ç‡ {memory.percent:.1f}%"
            )
            self.results["recommendations"].append(
                "å®ç°å†…å­˜é™åˆ¶ï¼Œå®šæœŸæ¸…ç†ç¼“å­˜ï¼Œä¼˜åŒ–æ•°æ®ç»“æ„"
            )
        
        print(f"  CPUä½¿ç”¨: {cpu_percent:.1f}%")
        print(f"  å†…å­˜ä½¿ç”¨: {memory.percent:.1f}%")
        print(f"  ç£ç›˜ä½¿ç”¨: {disk.percent:.1f}%")
        print(f"  RAGè¿›ç¨‹æ•°: {len(rag_processes)}")
        
        return result
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("=" * 60)
        print("RAG-Anything API å¿«é€Ÿæ€§èƒ½æµ‹è¯•")
        print("=" * 60)
        
        # æ£€æŸ¥APIå¥åº·
        if not await self.check_api_health():
            print("\nâŒ APIä¸å¯ç”¨ï¼Œè¯·å…ˆå¯åŠ¨APIæœåŠ¡å™¨:")
            print("   cd RAG-Anything/api")
            print("   python rag_api_server.py")
            return
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        self.results["tests"]["batch_processing"] = await self.test_serial_batch_processing()
        self.results["tests"]["memory_leak"] = await self.test_memory_leak()
        self.results["tests"]["cache_efficiency"] = await self.test_cache_efficiency()
        self.results["tests"]["concurrent_requests"] = await self.test_concurrent_requests()
        self.results["tests"]["resource_usage"] = await self.test_resource_usage()
        
        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report()
    
    def _generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("æµ‹è¯•ç»“æœæ€»ç»“")
        print("=" * 60)
        
        # é—®é¢˜æ€»ç»“
        if self.results["issues_found"]:
            print("\nğŸ”´ å‘ç°çš„é—®é¢˜:")
            for i, issue in enumerate(self.results["issues_found"], 1):
                print(f"  {i}. {issue}")
        else:
            print("\nâœ… æœªå‘ç°æ˜æ˜¾æ€§èƒ½é—®é¢˜")
        
        # ä¼˜åŒ–å»ºè®®
        if self.results["recommendations"]:
            print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for i, rec in enumerate(self.results["recommendations"], 1):
                print(f"  {i}. {rec}")
        
        # æ€§èƒ½è¯„åˆ†
        score = self._calculate_performance_score()
        print(f"\nğŸ“Š æ€»ä½“æ€§èƒ½è¯„åˆ†: {score}/100")
        
        if score < 40:
            print("   è¯„çº§: ğŸ”´ å·® - éœ€è¦ç«‹å³ä¼˜åŒ–")
        elif score < 60:
            print("   è¯„çº§: ğŸŸ¡ ä¸­ç­‰ - å»ºè®®ä¼˜åŒ–")
        elif score < 80:
            print("   è¯„çº§: ğŸŸ¢ è‰¯å¥½ - å¯ä»¥ä¼˜åŒ–")
        else:
            print("   è¯„çº§: ğŸ¯ ä¼˜ç§€ - æ€§èƒ½è‰¯å¥½")
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"performance_test_report_{int(time.time())}.json"
        with open(report_file, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    def _calculate_performance_score(self) -> int:
        """è®¡ç®—æ€§èƒ½è¯„åˆ†"""
        score = 100
        
        # æ ¹æ®é—®é¢˜æ‰£åˆ†
        score -= len(self.results["issues_found"]) * 15
        
        # æ ¹æ®æµ‹è¯•ç»“æœè°ƒæ•´
        tests = self.results["tests"]
        
        # æ‰¹å¤„ç†å¹¶è¡Œæ€§
        if "batch_processing" in tests and not tests["batch_processing"].get("is_truly_parallel", True):
            score -= 20
        
        # å†…å­˜æ³„æ¼
        if "memory_leak" in tests and tests["memory_leak"].get("has_memory_leak", False):
            score -= 15
        
        # ç¼“å­˜æ•ˆç‡
        if "cache_efficiency" in tests and not tests["cache_efficiency"].get("cache_working", True):
            score -= 10
        
        # èµ„æºä½¿ç”¨
        if "resource_usage" in tests:
            resource = tests["resource_usage"]
            if resource.get("cpu_underutilized", False):
                score -= 10
            if resource.get("memory_pressure", False):
                score -= 15
        
        return max(0, min(100, score))


async def main():
    """ä¸»å‡½æ•°"""
    tester = QuickPerformanceTest()
    await tester.run_all_tests()


if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨RAG-Anything APIæ€§èƒ½æµ‹è¯•...")
    print("   ç¡®ä¿APIæœåŠ¡å™¨è¿è¡Œåœ¨ http://127.0.0.1:8001")
    print()
    
    asyncio.run(main())