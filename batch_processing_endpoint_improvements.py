
# åœ¨ /api/v1/documents/process/batch ç«¯ç‚¹ä¸­çš„æ”¹è¿›

async def process_documents_batch_enhanced(request: BatchProcessRequest):
    """å¢å¼ºçš„æ‰¹é‡æ–‡æ¡£å¤„ç†ç«¯ç‚¹ - åŒ…å«æ•°æ®ä¸€è‡´æ€§éªŒè¯"""
    
    # ... ç°æœ‰çš„åˆå§‹åŒ–ä»£ç  ...
    
    try:
        # ä½¿ç”¨å¢å¼ºçš„æ‰¹é‡å¤„ç†å™¨
        enhanced_processor = EnhancedBatchProcessor(WORKING_DIR)
        
        # æ‰§è¡Œå¢å¼ºçš„æ‰¹é‡å¤„ç†
        enhanced_result = await enhanced_processor.enhanced_batch_process_with_verification(
            file_paths=file_paths,
            rag_instance=rag,
            progress_callback=websocket_progress_callback,
            output_dir=OUTPUT_DIR,
            parse_method=parse_method,
            max_workers=max_workers,
            recursive=False,
            show_progress=True,
            lang="en",
            device=device_type
        )
        
        # å¤„ç†ç»“æœï¼Œé‡ç‚¹å…³æ³¨ä¸ä¸€è‡´çš„æ–‡æ¡£
        for file_path in file_paths:
            doc_info = path_to_doc[file_path]
            document_id = doc_info["document_id"]
            document = doc_info["document"]
            task_id = doc_info["task_id"]
            
            # æ£€æŸ¥è¯¥æ–‡ä»¶çš„ä¸€è‡´æ€§éªŒè¯ç»“æœ
            file_verification = next(
                (v for v in enhanced_result["verification_results"] if v["file_path"] == file_path),
                None
            )
            
            if file_verification and file_verification["is_consistent"]:
                # ä¸€è‡´æ€§éªŒè¯é€šè¿‡
                document["status"] = "completed"
                tasks[task_id]["status"] = "completed"
                tasks[task_id]["completed_at"] = datetime.now().isoformat()
                
                results.append({
                    "document_id": document_id,
                    "file_name": document["file_name"],
                    "status": "success",
                    "message": "æ–‡æ¡£æ‰¹é‡å¤„ç†æˆåŠŸå¹¶é€šè¿‡ä¸€è‡´æ€§éªŒè¯",
                    "task_id": task_id,
                    "verification_passed": True
                })
                started_count += 1
            else:
                # ä¸€è‡´æ€§éªŒè¯å¤±è´¥
                error_details = []
                if file_verification:
                    error_details = file_verification.get("errors", [])
                    missing_components = file_verification.get("missing_components", [])
                    if missing_components:
                        error_details.append(f"ç¼ºå¤±ç»„ä»¶: {', '.join(missing_components)}")
                
                error_msg = f"æ•°æ®ä¸€è‡´æ€§éªŒè¯å¤±è´¥: {'; '.join(error_details)}"
                
                document["status"] = "failed"
                document["error_category"] = "data_inconsistency"
                tasks[task_id]["status"] = "failed"
                tasks[task_id]["error"] = error_msg
                tasks[task_id]["updated_at"] = datetime.now().isoformat()
                
                results.append({
                    "document_id": document_id,
                    "file_name": document["file_name"],
                    "status": "failed",
                    "message": error_msg,
                    "task_id": task_id,
                    "verification_passed": False,
                    "missing_components": file_verification.get("missing_components", []) if file_verification else []
                })
                failed_count += 1
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        response_data = {
            "success": failed_count == 0,
            "started_count": started_count,
            "failed_count": failed_count,
            "total_requested": len(request.document_ids),
            "results": results,
            "batch_operation_id": batch_operation_id,
            "message": f"å¢å¼ºæ‰¹é‡å¤„ç†å®Œæˆ: {started_count} ä¸ªæˆåŠŸ, {failed_count} ä¸ªå¤±è´¥",
            "verification_summary": {
                "verified_consistent": enhanced_result["verified_consistent"],
                "verified_inconsistent": enhanced_result["verified_inconsistent"],
                "inconsistent_documents": len(enhanced_result["inconsistent_documents"])
            }
        }
        
        # å¦‚æœæœ‰ä¸ä¸€è‡´çš„æ–‡æ¡£ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
        if enhanced_result["inconsistent_documents"]:
            await send_processing_log(
                f"âš ï¸  å‘ç° {len(enhanced_result['inconsistent_documents'])} ä¸ªæ•°æ®ä¸ä¸€è‡´çš„æ–‡æ¡£", 
                "warning"
            )
            
            # è‡ªåŠ¨ç”Ÿæˆä¿®å¤å»ºè®®
            await send_processing_log(
                f"ğŸ’¡ å»ºè®®è¿è¡Œæ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å™¨è¿›è¡Œä¿®å¤: python data_consistency_checker.py", 
                "info"
            )
        
        return BatchProcessResponse(**response_data)
        
    except Exception as e:
        # ç°æœ‰çš„é”™è¯¯å¤„ç†é€»è¾‘...
        pass
    