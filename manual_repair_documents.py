#!/usr/bin/env python3
# æ‰‹åŠ¨ä¿®å¤RAGç³»ç»Ÿæ•°æ®ä¸ä¸€è‡´æ–‡æ¡£

import asyncio
import sys
import os
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/home/ragsvr/projects/ragsystem/RAG-Anything')

from raganything import RAGAnything, RAGAnythingConfig
from simple_qwen_embed import qwen_embed
from lightrag.llm.openai import openai_complete_if_cache
from lightrag.utils import EmbeddingFunc
from dotenv import load_dotenv
from data_consistency_checker import RAGDataConsistencyChecker

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(dotenv_path="/home/ragsvr/projects/ragsystem/.env")

async def manual_repair_documents():
    """æ‰‹åŠ¨ä¿®å¤æ•°æ®ä¸ä¸€è‡´çš„æ–‡æ¡£"""
    print("ğŸ”§ å¼€å§‹æ‰‹åŠ¨ä¿®å¤RAGç³»ç»Ÿæ•°æ®ä¸ä¸€è‡´...")
    
    # åˆå§‹åŒ–RAGç³»ç»Ÿ
    config = RAGAnythingConfig(
        working_dir="/home/ragsvr/projects/ragsystem/rag_storage",
        parser_output_dir="/home/ragsvr/projects/ragsystem/output"
    )

    # LLMå‡½æ•°
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "deepseek-chat",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url=os.getenv("LLM_BINDING_HOST", "https://api.deepseek.com/v1"),
            **kwargs,
        )

    # åµŒå…¥å‡½æ•°
    embedding_func = EmbeddingFunc(
        embedding_dim=1024,
        max_token_size=512,
        func=qwen_embed,
    )

    # åˆ›å»ºRAGå®ä¾‹
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        embedding_func=embedding_func,
    )

    await rag._ensure_lightrag_initialized()

    # åˆ›å»ºæ£€æŸ¥å™¨
    checker = RAGDataConsistencyChecker("/home/ragsvr/projects/ragsystem/rag_storage", "/home/ragsvr/projects/ragsystem/output")

    # æŸ¥æ‰¾å¯æ¢å¤çš„æ–‡æ¡£
    print("ğŸ“Š æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§...")
    failed_docs, recoverable_docs = checker.find_inconsistent_documents()
    
    print(f"å‘ç° {len(recoverable_docs)} ä¸ªå¯æ¢å¤çš„æ–‡æ¡£")
    
    # é‡ç‚¹ä¿®å¤ç›®æ ‡æ–‡æ¡£
    target_filename = "å›½å®¶ç”µç½‘æœ‰é™å…¬å¸ä¼ä¸šå¹´é‡‘ç®¡ç†åŠæ³•_1644559838997.pdf"
    target_doc = None
    for doc in recoverable_docs:
        if target_filename in doc['file_name']:
            target_doc = doc
            break
    
    if not target_doc:
        print(f"âŒ æœªæ‰¾åˆ°ç›®æ ‡æ–‡æ¡£: {target_filename}")
        return
    
    print(f"\nğŸ¯ å¼€å§‹ä¿®å¤ç›®æ ‡æ–‡æ¡£: {target_filename}")
    
    # æ‰‹åŠ¨æ¸…ç†å­˜å‚¨ä¸­çš„æ—§è®°å½•
    doc_id = target_doc['doc_id']
    print(f"æ¸…ç†æ—§è®°å½•: {doc_id}")
    
    # æ¸…ç†doc_status
    doc_status_path = "/home/ragsvr/projects/ragsystem/rag_storage/kv_store_doc_status.json"
    with open(doc_status_path, 'r', encoding='utf-8') as f:
        doc_status = json.load(f)
    
    if doc_id in doc_status:
        del doc_status[doc_id]
        with open(doc_status_path, 'w', encoding='utf-8') as f:
            json.dump(doc_status, f, ensure_ascii=False, indent=2)
        print("âœ… å·²æ¸…ç†doc_statusè®°å½•")
    
    # æ¸…ç†full_docsï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    full_docs_path = "/home/ragsvr/projects/ragsystem/rag_storage/kv_store_full_docs.json"
    with open(full_docs_path, 'r', encoding='utf-8') as f:
        full_docs = json.load(f)
    
    if doc_id in full_docs:
        del full_docs[doc_id]
        with open(full_docs_path, 'w', encoding='utf-8') as f:
            json.dump(full_docs, f, ensure_ascii=False, indent=2)
        print("âœ… å·²æ¸…ç†full_docsè®°å½•")
    
    # æŸ¥æ‰¾content_listæ–‡ä»¶
    base_name = target_filename.replace('.pdf', '')
    folder_paths = [
        os.path.join("/home/ragsvr/projects/ragsystem/output", base_name),
        os.path.join("/home/ragsvr/projects/ragsystem/output", base_name, 'auto'),
        os.path.join("/home/ragsvr/projects/ragsystem/output", base_name, base_name, 'auto'),
    ]
    
    content_list_files = [
        'content_list.json',
        f'{base_name}_content_list.json'
    ]
    
    content_list_path = None
    for folder_path in folder_paths:
        for filename_pattern in content_list_files:
            potential_path = os.path.join(folder_path, filename_pattern)
            if os.path.exists(potential_path):
                content_list_path = potential_path
                break
        if content_list_path:
            break
    
    if not content_list_path:
        print("âŒ æœªæ‰¾åˆ°content_listæ–‡ä»¶")
        return
    
    # åŠ è½½content_list
    print(f"ğŸ“„ åŠ è½½è§£æå†…å®¹: {content_list_path}")
    with open(content_list_path, 'r', encoding='utf-8') as f:
        content_list = json.load(f)
    
    print(f"å†…å®¹å—æ•°é‡: {len(content_list)}")
    
    # é‡æ–°æ’å…¥æ–‡æ¡£ï¼ˆè¿™ä¼šç”Ÿæˆæ–°çš„doc_idï¼‰
    print("ğŸ”„ é‡æ–°æ’å…¥æ–‡æ¡£...")
    try:
        await rag.insert_content_list(content_list, target_filename)
        print(f"âœ… æˆåŠŸä¿®å¤æ–‡æ¡£: {target_filename}")
        
        # æ£€æŸ¥ä¿®å¤ç»“æœ
        print("\nğŸ“Š æ£€æŸ¥ä¿®å¤ç»“æœ...")
        failed_docs_after, recoverable_docs_after = checker.find_inconsistent_documents()
        
        # æŸ¥çœ‹æ˜¯å¦è¿˜æœ‰è¿™ä¸ªæ–‡ä»¶åçš„é—®é¢˜
        still_has_issue = False
        for doc in recoverable_docs_after + failed_docs_after:
            if target_filename in doc['file_name']:
                still_has_issue = True
                break
        
        if still_has_issue:
            print("âš ï¸ æ–‡æ¡£ä»å­˜åœ¨é—®é¢˜")
        else:
            print("ğŸ‰ æ–‡æ¡£ä¿®å¤æˆåŠŸï¼")
            
    except Exception as e:
        print(f"âŒ ä¿®å¤å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(manual_repair_documents())